{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15df6199-91f6-49a8-81bd-7b6faf4396a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8584e9c-3839-4c05-982f-4b6494370be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyModel(\n",
      "  (linear1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "Linear(in_features=100, out_features=10, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0174, -0.0778, -0.1093,  ...,  0.0979, -0.0081, -0.0041],\n",
      "        [ 0.1256,  0.0919,  0.0076,  ..., -0.1165, -0.0993, -0.0662],\n",
      "        [-0.0404, -0.0788,  0.0359,  ..., -0.0355, -0.1396,  0.1382],\n",
      "        ...,\n",
      "        [-0.1368,  0.0951,  0.1267,  ...,  0.0827,  0.0506, -0.0497],\n",
      "        [-0.0367,  0.0051,  0.0769,  ..., -0.1374, -0.1198, -0.0870],\n",
      "        [-0.1407,  0.1023, -0.1034,  ..., -0.1308,  0.0207,  0.1021]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0585,  0.0307, -0.1308, -0.1237, -0.0584, -0.1303,  0.0506, -0.0699,\n",
      "        -0.1389, -0.0122,  0.0714,  0.0710,  0.1303, -0.1357,  0.0193, -0.0713,\n",
      "        -0.0764, -0.0793,  0.1267, -0.0035,  0.1242, -0.1234, -0.0926,  0.0757,\n",
      "         0.0342,  0.0658, -0.1058,  0.1012, -0.1365, -0.0473, -0.0915, -0.0518,\n",
      "         0.0126,  0.0168,  0.0889, -0.1373,  0.1157,  0.0682,  0.0542,  0.0147,\n",
      "         0.0608,  0.0827, -0.1340,  0.1006,  0.0704,  0.0640,  0.1188, -0.0963,\n",
      "         0.1009,  0.1071,  0.1331,  0.1109,  0.1377,  0.0622,  0.1347, -0.0335,\n",
      "         0.0570,  0.0121, -0.0226,  0.0495, -0.0070, -0.0753, -0.0437, -0.1266,\n",
      "         0.0106, -0.0401,  0.0356,  0.0256,  0.1189,  0.1296, -0.0200, -0.1019,\n",
      "         0.0625,  0.0361,  0.0993, -0.0360,  0.0029, -0.0130,  0.1358,  0.1288,\n",
      "         0.0993, -0.0486,  0.0643,  0.0224,  0.0362,  0.0528,  0.0472,  0.0602,\n",
      "         0.0946, -0.0453, -0.0944,  0.0400,  0.1393, -0.0802, -0.0418, -0.1064,\n",
      "        -0.0259, -0.0558, -0.0930,  0.1185], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0508,  0.0170,  0.0739,  0.0230, -0.0535, -0.0204,  0.0083, -0.0250,\n",
      "          0.0186, -0.0299,  0.0476, -0.0886, -0.0134,  0.0223, -0.0241, -0.0866,\n",
      "         -0.0018,  0.0061,  0.0208,  0.0128,  0.0906, -0.0189,  0.0166,  0.0870,\n",
      "         -0.0303, -0.0665, -0.0376,  0.0590, -0.0562,  0.0947,  0.0083,  0.0760,\n",
      "         -0.0192,  0.0348,  0.0451,  0.0297, -0.0669, -0.0327, -0.0893,  0.0758,\n",
      "          0.0613,  0.0435,  0.0954, -0.0499, -0.0454, -0.0445, -0.0973,  0.0580,\n",
      "          0.0709,  0.0447, -0.0897,  0.0950, -0.0820,  0.0341,  0.0774,  0.0781,\n",
      "          0.0475,  0.0009,  0.0654, -0.0825, -0.0529,  0.0865, -0.0752,  0.0420,\n",
      "          0.0609,  0.0199, -0.0920,  0.0039, -0.0074, -0.0640,  0.0142,  0.0521,\n",
      "         -0.0445, -0.0465,  0.0861, -0.0518,  0.0017,  0.0147, -0.0441,  0.0908,\n",
      "          0.0465,  0.0622, -0.0131,  0.0086, -0.0194,  0.0372, -0.0993,  0.0735,\n",
      "         -0.0042, -0.0925,  0.0558,  0.0431,  0.0849,  0.0364, -0.0195,  0.0197,\n",
      "          0.0251,  0.0443, -0.0577, -0.0339],\n",
      "        [ 0.0935,  0.0212, -0.0955, -0.0153, -0.0658,  0.0850, -0.0795,  0.0209,\n",
      "         -0.0420, -0.0901,  0.0248, -0.0690, -0.0484,  0.0529, -0.0093, -0.0109,\n",
      "         -0.0055,  0.0958, -0.0012,  0.0547,  0.0936,  0.0509,  0.0942, -0.0288,\n",
      "          0.0647,  0.0171, -0.0557,  0.0831, -0.0359, -0.0172, -0.0670, -0.0624,\n",
      "         -0.0885,  0.0045, -0.0143,  0.0623,  0.0120,  0.0515,  0.0852,  0.0826,\n",
      "          0.0621, -0.0775, -0.0651,  0.0708,  0.0142, -0.0646, -0.0274, -0.0849,\n",
      "         -0.0995,  0.0683,  0.0737,  0.0562,  0.0140, -0.0621, -0.0434,  0.0872,\n",
      "          0.0412,  0.0466,  0.0282, -0.0808, -0.0300, -0.0699, -0.0710, -0.0515,\n",
      "          0.0445, -0.0943, -0.0571, -0.0374, -0.0710,  0.0636,  0.0174,  0.0981,\n",
      "         -0.0356, -0.0837, -0.0486,  0.0759,  0.0108, -0.0574,  0.0295, -0.0625,\n",
      "          0.0796,  0.0877,  0.0950,  0.0699,  0.0656,  0.0011, -0.0122, -0.0539,\n",
      "          0.0882, -0.0762, -0.0575,  0.0274,  0.0261, -0.0321, -0.0246, -0.0881,\n",
      "         -0.0272, -0.0054, -0.0478,  0.0716],\n",
      "        [-0.0961, -0.0978, -0.0137,  0.0625, -0.0845, -0.0822, -0.0702,  0.0306,\n",
      "          0.0409,  0.0817,  0.0216, -0.0410, -0.0999,  0.0458, -0.0086, -0.0219,\n",
      "          0.0069,  0.0665, -0.0536, -0.0577, -0.0027,  0.0707, -0.0558,  0.0960,\n",
      "         -0.0917, -0.0150,  0.0554,  0.0734,  0.0248, -0.0384,  0.0239,  0.0714,\n",
      "         -0.0642,  0.0322, -0.0447,  0.0122,  0.0232, -0.0252,  0.0773,  0.0402,\n",
      "         -0.0663,  0.0401, -0.0776,  0.0974,  0.0901,  0.0246, -0.0419,  0.0592,\n",
      "         -0.0984,  0.0278, -0.0183, -0.0284, -0.0665, -0.0747, -0.0833, -0.0900,\n",
      "         -0.0549,  0.0957, -0.0250,  0.0482, -0.0937,  0.0823,  0.0543, -0.0895,\n",
      "         -0.0266,  0.0510, -0.0946, -0.0721, -0.0109,  0.0072,  0.0381,  0.0478,\n",
      "         -0.0833,  0.0324,  0.0916,  0.0509, -0.0419, -0.0288,  0.0570,  0.0572,\n",
      "         -0.0264, -0.0793,  0.0540, -0.0327, -0.0621, -0.0934, -0.0827,  0.0578,\n",
      "         -0.0807, -0.0555, -0.0787,  0.0837, -0.0008,  0.0886, -0.0097, -0.0183,\n",
      "          0.0047,  0.0676, -0.0421,  0.0561],\n",
      "        [-0.0498, -0.0168, -0.0851,  0.0847,  0.0186,  0.0241, -0.0205, -0.0230,\n",
      "         -0.0615, -0.0126, -0.0341, -0.0618,  0.0655,  0.0611, -0.0733, -0.0154,\n",
      "         -0.0254, -0.0573, -0.0277, -0.0641, -0.0031,  0.0986,  0.0279, -0.0069,\n",
      "         -0.0120, -0.0837, -0.0665, -0.0066, -0.0581,  0.0426,  0.0308,  0.0241,\n",
      "         -0.0847, -0.0331, -0.0621,  0.0170,  0.0709, -0.0651, -0.0944,  0.0602,\n",
      "         -0.0564,  0.0836,  0.0469, -0.0103,  0.0278,  0.0946,  0.0067,  0.0138,\n",
      "          0.0043,  0.0624, -0.0207, -0.0463,  0.0567,  0.0006,  0.0372, -0.0772,\n",
      "          0.0729,  0.0735, -0.0578, -0.0383, -0.0097, -0.0223,  0.0095,  0.0954,\n",
      "         -0.0829,  0.0138, -0.0514,  0.0361, -0.0463, -0.0014,  0.0153,  0.0370,\n",
      "          0.0260,  0.0384,  0.0892,  0.0698, -0.0896, -0.0773,  0.0946,  0.0506,\n",
      "          0.0416, -0.0363, -0.0853,  0.0584,  0.0017,  0.0499, -0.0976, -0.0756,\n",
      "          0.0708,  0.0257,  0.0315,  0.0160,  0.0810, -0.0003, -0.0436, -0.0685,\n",
      "         -0.0637, -0.0351,  0.0722,  0.0243],\n",
      "        [ 0.0385,  0.0438, -0.0647,  0.0614, -0.0376,  0.0904, -0.0377,  0.0025,\n",
      "         -0.0381,  0.0749, -0.0726, -0.0275,  0.0520,  0.0570,  0.0155,  0.0221,\n",
      "         -0.0479, -0.0819,  0.0139, -0.0857, -0.0028,  0.0886,  0.0787, -0.0067,\n",
      "         -0.0836,  0.0436,  0.0051, -0.0802, -0.0827, -0.0182, -0.0738, -0.0639,\n",
      "         -0.0291,  0.0897,  0.0629, -0.0640,  0.0318,  0.0367, -0.0043,  0.0774,\n",
      "          0.0177, -0.0489,  0.0290,  0.0918,  0.0757,  0.0076, -0.0841, -0.0622,\n",
      "         -0.0766, -0.0361,  0.0209, -0.0257,  0.0643, -0.0754,  0.0686, -0.0831,\n",
      "          0.0094, -0.0298,  0.0763, -0.0987, -0.0210, -0.0074, -0.0173, -0.0158,\n",
      "         -0.0330, -0.0332,  0.0843,  0.0841,  0.0678, -0.0348, -0.0595, -0.0032,\n",
      "         -0.0146,  0.0378, -0.0018, -0.0131,  0.0046, -0.0427,  0.0830, -0.0239,\n",
      "         -0.0168,  0.0402,  0.0191, -0.0373, -0.0996,  0.0671, -0.0023,  0.0362,\n",
      "         -0.0732,  0.0888, -0.0425,  0.0765,  0.0354, -0.0092,  0.0588,  0.0232,\n",
      "         -0.0219,  0.0438,  0.0605,  0.0643],\n",
      "        [ 0.0510, -0.0777, -0.0319,  0.0862,  0.0778, -0.0099, -0.0739, -0.0042,\n",
      "         -0.0244,  0.0487, -0.0382,  0.0902, -0.0559, -0.0577, -0.0787,  0.0351,\n",
      "          0.0911,  0.0636,  0.0029, -0.0606, -0.0860, -0.0834,  0.0379,  0.0664,\n",
      "         -0.0884,  0.0813, -0.0748,  0.0651,  0.0460, -0.0789,  0.0461,  0.0955,\n",
      "          0.0688,  0.0063,  0.0682, -0.0249, -0.0087, -0.0709, -0.0375, -0.0835,\n",
      "          0.0950,  0.0799,  0.0485,  0.0785, -0.0697, -0.0088, -0.0131,  0.0527,\n",
      "          0.0894,  0.0189,  0.0815, -0.0794,  0.0965, -0.0201,  0.0517,  0.0424,\n",
      "          0.0308,  0.0013, -0.0874, -0.0072, -0.0282, -0.0982,  0.0526,  0.0083,\n",
      "          0.0586,  0.0016, -0.0349, -0.0739,  0.0263,  0.0445, -0.0094,  0.0581,\n",
      "         -0.0868,  0.0149,  0.0531,  0.0471,  0.0400,  0.0480, -0.0805,  0.0469,\n",
      "         -0.0221, -0.0778, -0.0467, -0.0838,  0.0220,  0.0834, -0.0054,  0.0173,\n",
      "         -0.0832,  0.0991, -0.0497, -0.0431, -0.0705, -0.0809,  0.0629,  0.0637,\n",
      "         -0.0902, -0.0915,  0.0438,  0.0150],\n",
      "        [-0.0598, -0.0094, -0.0447,  0.0098,  0.0195, -0.0066,  0.0876, -0.0824,\n",
      "         -0.0780, -0.0025, -0.0058, -0.0764, -0.0861,  0.0486, -0.0217, -0.0939,\n",
      "          0.0295, -0.0073,  0.0757,  0.0746,  0.0038, -0.0284, -0.0753,  0.0542,\n",
      "         -0.0210,  0.0718,  0.0868,  0.0684, -0.0990,  0.0616,  0.0353, -0.0553,\n",
      "          0.0267, -0.0245, -0.0848,  0.0579,  0.0701,  0.0522,  0.0868,  0.0663,\n",
      "         -0.0749, -0.0847, -0.0134,  0.0346, -0.0367,  0.0569,  0.0965,  0.0385,\n",
      "          0.0045, -0.0482,  0.0494,  0.0459,  0.0708, -0.0974, -0.0275, -0.0302,\n",
      "          0.0958,  0.0451, -0.0563,  0.0579,  0.0254,  0.0125, -0.0109,  0.0925,\n",
      "         -0.0874,  0.0771, -0.0337,  0.0044,  0.0082, -0.0989,  0.0125, -0.0683,\n",
      "         -0.0141,  0.0611,  0.0535, -0.0340,  0.0114, -0.0884, -0.0098, -0.0751,\n",
      "         -0.0914,  0.0427, -0.0305, -0.0510, -0.0753, -0.0776, -0.0482, -0.0867,\n",
      "          0.0082, -0.0087,  0.0124, -0.0082,  0.0615,  0.0742,  0.0884,  0.0161,\n",
      "          0.0005, -0.0469,  0.0808, -0.0241],\n",
      "        [ 0.0780,  0.0589,  0.0101,  0.0680,  0.0960, -0.0070,  0.0489,  0.0440,\n",
      "          0.0935,  0.0271, -0.0583, -0.0189,  0.0239,  0.0398,  0.0475,  0.0211,\n",
      "         -0.0297, -0.0484,  0.0244,  0.0665,  0.0341, -0.0853,  0.0976, -0.0135,\n",
      "          0.0290,  0.0164,  0.0873, -0.0958, -0.0659, -0.0568,  0.0379, -0.0445,\n",
      "          0.0717,  0.0675, -0.0047,  0.0022, -0.0178,  0.0424,  0.0064,  0.0250,\n",
      "          0.0615,  0.0683, -0.0855, -0.0680, -0.0132,  0.0962,  0.0431, -0.0127,\n",
      "         -0.0898, -0.0574, -0.0041,  0.0403, -0.0242, -0.0858,  0.0297, -0.0111,\n",
      "         -0.0289,  0.0387, -0.0364, -0.0209, -0.0052,  0.0061,  0.0370,  0.0873,\n",
      "         -0.0518, -0.0196,  0.0624, -0.0068,  0.0727, -0.0596,  0.0247, -0.0048,\n",
      "         -0.0134, -0.0016, -0.0021, -0.0415, -0.0761,  0.0204,  0.0380, -0.0039,\n",
      "         -0.0382,  0.0498, -0.0068, -0.0528,  0.0158, -0.0862,  0.0679, -0.0922,\n",
      "         -0.0215, -0.0249, -0.0572, -0.0068, -0.0165,  0.0032, -0.0795, -0.0573,\n",
      "          0.0843, -0.0242, -0.0599, -0.0865],\n",
      "        [-0.0631, -0.0266,  0.0439, -0.0009,  0.0119,  0.0156, -0.0751, -0.0736,\n",
      "          0.0575,  0.0027, -0.0357,  0.0780,  0.0031, -0.0196, -0.0859,  0.0603,\n",
      "          0.0744, -0.0826, -0.0940,  0.0236,  0.0094, -0.0513,  0.0103,  0.0056,\n",
      "          0.0839, -0.0333,  0.0583, -0.0113,  0.0237, -0.0350, -0.0775, -0.0839,\n",
      "          0.0792, -0.0045, -0.0682,  0.0247,  0.0569, -0.0371, -0.0536,  0.0177,\n",
      "         -0.0122, -0.0065,  0.0651, -0.0858,  0.0283,  0.0855, -0.0912,  0.0246,\n",
      "          0.0339, -0.0248,  0.0115,  0.0541, -0.0109,  0.0597, -0.0925,  0.0258,\n",
      "          0.0673,  0.0312, -0.0552,  0.0513, -0.0944, -0.0500,  0.0341, -0.0286,\n",
      "          0.0739,  0.0691, -0.0945,  0.0670,  0.0559,  0.0001, -0.0871, -0.0823,\n",
      "         -0.0021,  0.0208,  0.0696,  0.0557,  0.0089, -0.0174, -0.0529,  0.0534,\n",
      "          0.0598,  0.0980,  0.0023,  0.0429,  0.0213, -0.0113, -0.0967, -0.0725,\n",
      "         -0.0456, -0.0768, -0.0715, -0.0773,  0.0748, -0.0477, -0.0497,  0.0605,\n",
      "         -0.0023, -0.0534, -0.0583,  0.0757],\n",
      "        [-0.0303, -0.0136,  0.0858,  0.0235, -0.0661,  0.0277,  0.0119, -0.0604,\n",
      "          0.0706, -0.0673,  0.0011, -0.0391, -0.0403,  0.0246, -0.0236,  0.0635,\n",
      "         -0.0885,  0.0211,  0.0014,  0.0319,  0.0752, -0.0286,  0.0930,  0.0637,\n",
      "          0.0081,  0.0942,  0.0865,  0.0898, -0.0738, -0.0763,  0.0743, -0.0169,\n",
      "          0.0216,  0.0064, -0.0162, -0.0611,  0.0052, -0.0318, -0.0376, -0.0452,\n",
      "         -0.0745, -0.0415,  0.0781,  0.0189, -0.0077, -0.0878,  0.0940,  0.0952,\n",
      "          0.0634, -0.0467,  0.0742, -0.0343,  0.0429,  0.0252, -0.0860,  0.0363,\n",
      "         -0.0559, -0.0009, -0.0369,  0.0512,  0.0835, -0.0695, -0.0873,  0.0355,\n",
      "          0.0407,  0.0988,  0.0441, -0.0359,  0.0223,  0.0264,  0.0200,  0.0238,\n",
      "         -0.0851,  0.0565,  0.0776, -0.0347,  0.0468,  0.0282,  0.0525, -0.0133,\n",
      "         -0.0546,  0.0026, -0.0285,  0.0268, -0.0916,  0.0981, -0.0507,  0.0597,\n",
      "         -0.0723, -0.0203,  0.0714, -0.0273,  0.0017,  0.0469,  0.0353,  0.0123,\n",
      "         -0.0303, -0.0643,  0.0219,  0.0220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0107, -0.0607,  0.0901,  0.0422,  0.0499, -0.0170,  0.0013, -0.0391,\n",
      "         0.0147,  0.0489], requires_grad=True)\n",
      "Layer params: \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.0508,  0.0170,  0.0739,  0.0230, -0.0535, -0.0204,  0.0083, -0.0250,\n",
      "          0.0186, -0.0299,  0.0476, -0.0886, -0.0134,  0.0223, -0.0241, -0.0866,\n",
      "         -0.0018,  0.0061,  0.0208,  0.0128,  0.0906, -0.0189,  0.0166,  0.0870,\n",
      "         -0.0303, -0.0665, -0.0376,  0.0590, -0.0562,  0.0947,  0.0083,  0.0760,\n",
      "         -0.0192,  0.0348,  0.0451,  0.0297, -0.0669, -0.0327, -0.0893,  0.0758,\n",
      "          0.0613,  0.0435,  0.0954, -0.0499, -0.0454, -0.0445, -0.0973,  0.0580,\n",
      "          0.0709,  0.0447, -0.0897,  0.0950, -0.0820,  0.0341,  0.0774,  0.0781,\n",
      "          0.0475,  0.0009,  0.0654, -0.0825, -0.0529,  0.0865, -0.0752,  0.0420,\n",
      "          0.0609,  0.0199, -0.0920,  0.0039, -0.0074, -0.0640,  0.0142,  0.0521,\n",
      "         -0.0445, -0.0465,  0.0861, -0.0518,  0.0017,  0.0147, -0.0441,  0.0908,\n",
      "          0.0465,  0.0622, -0.0131,  0.0086, -0.0194,  0.0372, -0.0993,  0.0735,\n",
      "         -0.0042, -0.0925,  0.0558,  0.0431,  0.0849,  0.0364, -0.0195,  0.0197,\n",
      "          0.0251,  0.0443, -0.0577, -0.0339],\n",
      "        [ 0.0935,  0.0212, -0.0955, -0.0153, -0.0658,  0.0850, -0.0795,  0.0209,\n",
      "         -0.0420, -0.0901,  0.0248, -0.0690, -0.0484,  0.0529, -0.0093, -0.0109,\n",
      "         -0.0055,  0.0958, -0.0012,  0.0547,  0.0936,  0.0509,  0.0942, -0.0288,\n",
      "          0.0647,  0.0171, -0.0557,  0.0831, -0.0359, -0.0172, -0.0670, -0.0624,\n",
      "         -0.0885,  0.0045, -0.0143,  0.0623,  0.0120,  0.0515,  0.0852,  0.0826,\n",
      "          0.0621, -0.0775, -0.0651,  0.0708,  0.0142, -0.0646, -0.0274, -0.0849,\n",
      "         -0.0995,  0.0683,  0.0737,  0.0562,  0.0140, -0.0621, -0.0434,  0.0872,\n",
      "          0.0412,  0.0466,  0.0282, -0.0808, -0.0300, -0.0699, -0.0710, -0.0515,\n",
      "          0.0445, -0.0943, -0.0571, -0.0374, -0.0710,  0.0636,  0.0174,  0.0981,\n",
      "         -0.0356, -0.0837, -0.0486,  0.0759,  0.0108, -0.0574,  0.0295, -0.0625,\n",
      "          0.0796,  0.0877,  0.0950,  0.0699,  0.0656,  0.0011, -0.0122, -0.0539,\n",
      "          0.0882, -0.0762, -0.0575,  0.0274,  0.0261, -0.0321, -0.0246, -0.0881,\n",
      "         -0.0272, -0.0054, -0.0478,  0.0716],\n",
      "        [-0.0961, -0.0978, -0.0137,  0.0625, -0.0845, -0.0822, -0.0702,  0.0306,\n",
      "          0.0409,  0.0817,  0.0216, -0.0410, -0.0999,  0.0458, -0.0086, -0.0219,\n",
      "          0.0069,  0.0665, -0.0536, -0.0577, -0.0027,  0.0707, -0.0558,  0.0960,\n",
      "         -0.0917, -0.0150,  0.0554,  0.0734,  0.0248, -0.0384,  0.0239,  0.0714,\n",
      "         -0.0642,  0.0322, -0.0447,  0.0122,  0.0232, -0.0252,  0.0773,  0.0402,\n",
      "         -0.0663,  0.0401, -0.0776,  0.0974,  0.0901,  0.0246, -0.0419,  0.0592,\n",
      "         -0.0984,  0.0278, -0.0183, -0.0284, -0.0665, -0.0747, -0.0833, -0.0900,\n",
      "         -0.0549,  0.0957, -0.0250,  0.0482, -0.0937,  0.0823,  0.0543, -0.0895,\n",
      "         -0.0266,  0.0510, -0.0946, -0.0721, -0.0109,  0.0072,  0.0381,  0.0478,\n",
      "         -0.0833,  0.0324,  0.0916,  0.0509, -0.0419, -0.0288,  0.0570,  0.0572,\n",
      "         -0.0264, -0.0793,  0.0540, -0.0327, -0.0621, -0.0934, -0.0827,  0.0578,\n",
      "         -0.0807, -0.0555, -0.0787,  0.0837, -0.0008,  0.0886, -0.0097, -0.0183,\n",
      "          0.0047,  0.0676, -0.0421,  0.0561],\n",
      "        [-0.0498, -0.0168, -0.0851,  0.0847,  0.0186,  0.0241, -0.0205, -0.0230,\n",
      "         -0.0615, -0.0126, -0.0341, -0.0618,  0.0655,  0.0611, -0.0733, -0.0154,\n",
      "         -0.0254, -0.0573, -0.0277, -0.0641, -0.0031,  0.0986,  0.0279, -0.0069,\n",
      "         -0.0120, -0.0837, -0.0665, -0.0066, -0.0581,  0.0426,  0.0308,  0.0241,\n",
      "         -0.0847, -0.0331, -0.0621,  0.0170,  0.0709, -0.0651, -0.0944,  0.0602,\n",
      "         -0.0564,  0.0836,  0.0469, -0.0103,  0.0278,  0.0946,  0.0067,  0.0138,\n",
      "          0.0043,  0.0624, -0.0207, -0.0463,  0.0567,  0.0006,  0.0372, -0.0772,\n",
      "          0.0729,  0.0735, -0.0578, -0.0383, -0.0097, -0.0223,  0.0095,  0.0954,\n",
      "         -0.0829,  0.0138, -0.0514,  0.0361, -0.0463, -0.0014,  0.0153,  0.0370,\n",
      "          0.0260,  0.0384,  0.0892,  0.0698, -0.0896, -0.0773,  0.0946,  0.0506,\n",
      "          0.0416, -0.0363, -0.0853,  0.0584,  0.0017,  0.0499, -0.0976, -0.0756,\n",
      "          0.0708,  0.0257,  0.0315,  0.0160,  0.0810, -0.0003, -0.0436, -0.0685,\n",
      "         -0.0637, -0.0351,  0.0722,  0.0243],\n",
      "        [ 0.0385,  0.0438, -0.0647,  0.0614, -0.0376,  0.0904, -0.0377,  0.0025,\n",
      "         -0.0381,  0.0749, -0.0726, -0.0275,  0.0520,  0.0570,  0.0155,  0.0221,\n",
      "         -0.0479, -0.0819,  0.0139, -0.0857, -0.0028,  0.0886,  0.0787, -0.0067,\n",
      "         -0.0836,  0.0436,  0.0051, -0.0802, -0.0827, -0.0182, -0.0738, -0.0639,\n",
      "         -0.0291,  0.0897,  0.0629, -0.0640,  0.0318,  0.0367, -0.0043,  0.0774,\n",
      "          0.0177, -0.0489,  0.0290,  0.0918,  0.0757,  0.0076, -0.0841, -0.0622,\n",
      "         -0.0766, -0.0361,  0.0209, -0.0257,  0.0643, -0.0754,  0.0686, -0.0831,\n",
      "          0.0094, -0.0298,  0.0763, -0.0987, -0.0210, -0.0074, -0.0173, -0.0158,\n",
      "         -0.0330, -0.0332,  0.0843,  0.0841,  0.0678, -0.0348, -0.0595, -0.0032,\n",
      "         -0.0146,  0.0378, -0.0018, -0.0131,  0.0046, -0.0427,  0.0830, -0.0239,\n",
      "         -0.0168,  0.0402,  0.0191, -0.0373, -0.0996,  0.0671, -0.0023,  0.0362,\n",
      "         -0.0732,  0.0888, -0.0425,  0.0765,  0.0354, -0.0092,  0.0588,  0.0232,\n",
      "         -0.0219,  0.0438,  0.0605,  0.0643],\n",
      "        [ 0.0510, -0.0777, -0.0319,  0.0862,  0.0778, -0.0099, -0.0739, -0.0042,\n",
      "         -0.0244,  0.0487, -0.0382,  0.0902, -0.0559, -0.0577, -0.0787,  0.0351,\n",
      "          0.0911,  0.0636,  0.0029, -0.0606, -0.0860, -0.0834,  0.0379,  0.0664,\n",
      "         -0.0884,  0.0813, -0.0748,  0.0651,  0.0460, -0.0789,  0.0461,  0.0955,\n",
      "          0.0688,  0.0063,  0.0682, -0.0249, -0.0087, -0.0709, -0.0375, -0.0835,\n",
      "          0.0950,  0.0799,  0.0485,  0.0785, -0.0697, -0.0088, -0.0131,  0.0527,\n",
      "          0.0894,  0.0189,  0.0815, -0.0794,  0.0965, -0.0201,  0.0517,  0.0424,\n",
      "          0.0308,  0.0013, -0.0874, -0.0072, -0.0282, -0.0982,  0.0526,  0.0083,\n",
      "          0.0586,  0.0016, -0.0349, -0.0739,  0.0263,  0.0445, -0.0094,  0.0581,\n",
      "         -0.0868,  0.0149,  0.0531,  0.0471,  0.0400,  0.0480, -0.0805,  0.0469,\n",
      "         -0.0221, -0.0778, -0.0467, -0.0838,  0.0220,  0.0834, -0.0054,  0.0173,\n",
      "         -0.0832,  0.0991, -0.0497, -0.0431, -0.0705, -0.0809,  0.0629,  0.0637,\n",
      "         -0.0902, -0.0915,  0.0438,  0.0150],\n",
      "        [-0.0598, -0.0094, -0.0447,  0.0098,  0.0195, -0.0066,  0.0876, -0.0824,\n",
      "         -0.0780, -0.0025, -0.0058, -0.0764, -0.0861,  0.0486, -0.0217, -0.0939,\n",
      "          0.0295, -0.0073,  0.0757,  0.0746,  0.0038, -0.0284, -0.0753,  0.0542,\n",
      "         -0.0210,  0.0718,  0.0868,  0.0684, -0.0990,  0.0616,  0.0353, -0.0553,\n",
      "          0.0267, -0.0245, -0.0848,  0.0579,  0.0701,  0.0522,  0.0868,  0.0663,\n",
      "         -0.0749, -0.0847, -0.0134,  0.0346, -0.0367,  0.0569,  0.0965,  0.0385,\n",
      "          0.0045, -0.0482,  0.0494,  0.0459,  0.0708, -0.0974, -0.0275, -0.0302,\n",
      "          0.0958,  0.0451, -0.0563,  0.0579,  0.0254,  0.0125, -0.0109,  0.0925,\n",
      "         -0.0874,  0.0771, -0.0337,  0.0044,  0.0082, -0.0989,  0.0125, -0.0683,\n",
      "         -0.0141,  0.0611,  0.0535, -0.0340,  0.0114, -0.0884, -0.0098, -0.0751,\n",
      "         -0.0914,  0.0427, -0.0305, -0.0510, -0.0753, -0.0776, -0.0482, -0.0867,\n",
      "          0.0082, -0.0087,  0.0124, -0.0082,  0.0615,  0.0742,  0.0884,  0.0161,\n",
      "          0.0005, -0.0469,  0.0808, -0.0241],\n",
      "        [ 0.0780,  0.0589,  0.0101,  0.0680,  0.0960, -0.0070,  0.0489,  0.0440,\n",
      "          0.0935,  0.0271, -0.0583, -0.0189,  0.0239,  0.0398,  0.0475,  0.0211,\n",
      "         -0.0297, -0.0484,  0.0244,  0.0665,  0.0341, -0.0853,  0.0976, -0.0135,\n",
      "          0.0290,  0.0164,  0.0873, -0.0958, -0.0659, -0.0568,  0.0379, -0.0445,\n",
      "          0.0717,  0.0675, -0.0047,  0.0022, -0.0178,  0.0424,  0.0064,  0.0250,\n",
      "          0.0615,  0.0683, -0.0855, -0.0680, -0.0132,  0.0962,  0.0431, -0.0127,\n",
      "         -0.0898, -0.0574, -0.0041,  0.0403, -0.0242, -0.0858,  0.0297, -0.0111,\n",
      "         -0.0289,  0.0387, -0.0364, -0.0209, -0.0052,  0.0061,  0.0370,  0.0873,\n",
      "         -0.0518, -0.0196,  0.0624, -0.0068,  0.0727, -0.0596,  0.0247, -0.0048,\n",
      "         -0.0134, -0.0016, -0.0021, -0.0415, -0.0761,  0.0204,  0.0380, -0.0039,\n",
      "         -0.0382,  0.0498, -0.0068, -0.0528,  0.0158, -0.0862,  0.0679, -0.0922,\n",
      "         -0.0215, -0.0249, -0.0572, -0.0068, -0.0165,  0.0032, -0.0795, -0.0573,\n",
      "          0.0843, -0.0242, -0.0599, -0.0865],\n",
      "        [-0.0631, -0.0266,  0.0439, -0.0009,  0.0119,  0.0156, -0.0751, -0.0736,\n",
      "          0.0575,  0.0027, -0.0357,  0.0780,  0.0031, -0.0196, -0.0859,  0.0603,\n",
      "          0.0744, -0.0826, -0.0940,  0.0236,  0.0094, -0.0513,  0.0103,  0.0056,\n",
      "          0.0839, -0.0333,  0.0583, -0.0113,  0.0237, -0.0350, -0.0775, -0.0839,\n",
      "          0.0792, -0.0045, -0.0682,  0.0247,  0.0569, -0.0371, -0.0536,  0.0177,\n",
      "         -0.0122, -0.0065,  0.0651, -0.0858,  0.0283,  0.0855, -0.0912,  0.0246,\n",
      "          0.0339, -0.0248,  0.0115,  0.0541, -0.0109,  0.0597, -0.0925,  0.0258,\n",
      "          0.0673,  0.0312, -0.0552,  0.0513, -0.0944, -0.0500,  0.0341, -0.0286,\n",
      "          0.0739,  0.0691, -0.0945,  0.0670,  0.0559,  0.0001, -0.0871, -0.0823,\n",
      "         -0.0021,  0.0208,  0.0696,  0.0557,  0.0089, -0.0174, -0.0529,  0.0534,\n",
      "          0.0598,  0.0980,  0.0023,  0.0429,  0.0213, -0.0113, -0.0967, -0.0725,\n",
      "         -0.0456, -0.0768, -0.0715, -0.0773,  0.0748, -0.0477, -0.0497,  0.0605,\n",
      "         -0.0023, -0.0534, -0.0583,  0.0757],\n",
      "        [-0.0303, -0.0136,  0.0858,  0.0235, -0.0661,  0.0277,  0.0119, -0.0604,\n",
      "          0.0706, -0.0673,  0.0011, -0.0391, -0.0403,  0.0246, -0.0236,  0.0635,\n",
      "         -0.0885,  0.0211,  0.0014,  0.0319,  0.0752, -0.0286,  0.0930,  0.0637,\n",
      "          0.0081,  0.0942,  0.0865,  0.0898, -0.0738, -0.0763,  0.0743, -0.0169,\n",
      "          0.0216,  0.0064, -0.0162, -0.0611,  0.0052, -0.0318, -0.0376, -0.0452,\n",
      "         -0.0745, -0.0415,  0.0781,  0.0189, -0.0077, -0.0878,  0.0940,  0.0952,\n",
      "          0.0634, -0.0467,  0.0742, -0.0343,  0.0429,  0.0252, -0.0860,  0.0363,\n",
      "         -0.0559, -0.0009, -0.0369,  0.0512,  0.0835, -0.0695, -0.0873,  0.0355,\n",
      "          0.0407,  0.0988,  0.0441, -0.0359,  0.0223,  0.0264,  0.0200,  0.0238,\n",
      "         -0.0851,  0.0565,  0.0776, -0.0347,  0.0468,  0.0282,  0.0525, -0.0133,\n",
      "         -0.0546,  0.0026, -0.0285,  0.0268, -0.0916,  0.0981, -0.0507,  0.0597,\n",
      "         -0.0723, -0.0203,  0.0714, -0.0273,  0.0017,  0.0469,  0.0353,  0.0123,\n",
      "         -0.0303, -0.0643,  0.0219,  0.0220]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0107, -0.0607,  0.0901,  0.0422,  0.0499, -0.0170,  0.0013, -0.0391,\n",
      "         0.0147,  0.0489], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "# all weights and biases are part of the nn.Parameter class!\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(50, 100)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(100, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        #return self.softmax(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "        \n",
    "model = TinyModel()\n",
    "# da model class\n",
    "print(TinyModel())\n",
    "# model object\n",
    "print(model)\n",
    "# a layer\n",
    "print(model.linear2)\n",
    "# model params\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "# layer parameters\n",
    "print(\"Layer params: \\n\")\n",
    "for param in model.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9dc7b-05d0-451c-b0e9-0939a72c383c",
   "metadata": {},
   "source": [
    "## Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6014c9-0d47-4aa9-99de-9e56195a4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # not using any stride, input is 1x32x32\n",
    "        # 1 input img channel cuz b&w, 6 output features/channel, 5x5 convolutional kernel\n",
    "        self.conv1 = torch.nn.Conv2D(1, 6, 5)\n",
    "        # output here is 6x28x28\n",
    "        # 6 input channels, 16 output features, 3x3 conv kernel\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = torch.nn.Linear(16*6*6, 120) # reshaping inputs first. figured out the dimensions from the forward methods, post relu and max pooling\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Note: we are using the functional api here, though using nn.ReLU() and nn.MaxPool2d() are also perfectly acceptable, as they are also calling these functional methods in their forward() calls\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # max pooling over 2x2 window\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # can also concat em together like this but looks disgusting to me\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # can just use 2 instead of passing a tuple as it's a square matrix anyways\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03371e-fd30-481d-902b-9f406e6d526e",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c5c2b2-94f7-4b69-9d5c-652c085f1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "    \"\"\"Is a Part of Speech(PoS) tagger which tells if a word is a verb, noun and stuff\"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # embeds words\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        # lstm takes embeddings as inputs and produces an internal feature representation\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # maps hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94956903-9668-4c8a-b4a2-ce6f659c0405",
   "metadata": {},
   "source": [
    "## misc stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "148ae254-d35e-4e30-b355-f1c4290938a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.7645, 22.4922,  9.7837,  9.7792],\n",
      "         [13.6098, 13.6717,  6.2189, 22.7175],\n",
      "         [ 6.7936,  9.2349, 23.6158, 24.1898],\n",
      "         [12.3069,  7.4667,  5.3526, 19.6663]]])\n",
      "tensor(13.4790)\n",
      "tensor([[[-0.6954,  1.7274, -0.5156, -0.5164],\n",
      "         [-0.0760, -0.0655, -1.3399,  1.4814],\n",
      "         [-1.1465, -0.8411,  0.9579,  1.0297],\n",
      "         [ 0.2016, -0.6783, -1.0627,  1.5395]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(-5.9605e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensur = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(tensur)\n",
    "\n",
    "print(tensur.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(tensur)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean()) # voila, nearly zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2828f50-2e82-439f-b546-05401e360d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4052, 0.2455, 0.5260, 0.1695],\n",
      "         [0.1481, 0.4265, 0.2333, 0.3349],\n",
      "         [0.9495, 0.9817, 0.5258, 0.8193],\n",
      "         [0.5973, 0.3116, 0.7683, 0.0919]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 9.8167, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "tensur = torch.rand(1, 4, 4)\n",
    "\n",
    "dropoutt = torch.nn.Dropout(p=0.9)\n",
    "print(tensur)\n",
    "print(dropoutt(tensur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affeab9-2f54-4aa3-b0c2-a8a04a0d94c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
